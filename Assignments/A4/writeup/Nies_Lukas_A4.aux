\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {0}Policies}{1}{section.0}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.1}List of Collaborators}{1}{subsection.0.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.2}List of Acknowledgments}{1}{subsection.0.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {0.3}Policies}{1}{subsection.0.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Convexity: Linear and Logistic Regression}{2}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Neural Networks and Non-convex optimization}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Computational Complexity}{2}{subsection.2.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Forwardpass without mini batches\relax }}{2}{algorithm.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:FWP}{{1}{2}{Forwardpass without mini batches\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Forwardpass with mini batches\relax }}{2}{algorithm.2}}
\newlabel{alg:FWPmini}{{2}{2}{Forwardpass with mini batches\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Saddle Points and Symmetry}{3}{subsection.2.2}}
\newlabel{eq:MLPtop}{{9}{4}{Saddle Points and Symmetry}{equation.2.9}{}}
\newlabel{MLParbitrary}{{10}{4}{Saddle Points and Symmetry}{equation.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Representation and Non-linear Decision Boundaries}{4}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}MLPs on MNIST}{6}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}One hidden layer MLP}{6}{subsection.3.1}}
\bibstyle{unsrt}
\bibdata{./bib}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Squared loss and misclassification error for the one layer hidden network with sigmoid transfer functions. I chose displaying the misclassification over a wider range since there are some interesting features happening above $20\%$.\relax }}{7}{figure.caption.2}}
\newlabel{fig:sigmoid}{{1}{7}{Squared loss and misclassification error for the one layer hidden network with sigmoid transfer functions. I chose displaying the misclassification over a wider range since there are some interesting features happening above $20\%$.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{7}{figure.caption.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visualization of the weights for ten nodes in the hidden layer after sigmoid transfer.\relax }}{8}{figure.caption.3}}
\newlabel{fig:sigmoid_weights}{{2}{8}{Visualization of the weights for ten nodes in the hidden layer after sigmoid transfer.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Squared loss and misclassification error for the one layer hidden network with sigmoid transfer functions. I chose displaying the misclassification over a wider range since there are some interesting features happening above $20\%$.\relax }}{8}{figure.caption.4}}
\newlabel{fig:relu}{{3}{8}{Squared loss and misclassification error for the one layer hidden network with sigmoid transfer functions. I chose displaying the misclassification over a wider range since there are some interesting features happening above $20\%$.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the weights for ten nodes in the hidden layer after relu transfer.\relax }}{9}{figure.caption.5}}
\newlabel{fig:relu_weights}{{4}{9}{Visualization of the weights for ten nodes in the hidden layer after relu transfer.\relax }{figure.caption.5}{}}
